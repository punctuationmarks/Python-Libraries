{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic NN model with Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fLr1rwITVV_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Basic Neural Network model built with Pytorch\n",
        "### (Not using transfer learning)"
      ]
    },
    {
      "metadata": {
        "id": "nNgTlAp68xhC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# MNIST Fashion is built into Pytorch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim, utils\n",
        "\n",
        "# to show the images\n",
        "import helper # this doesn't work with Google Colab\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zKCjqulH84i0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.ToTensor(), \n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UdSXKAXf856R",
        "colab_type": "code",
        "outputId": "09f0e4c5-0932-45ba-a9c1-99109a41761e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=train_transforms)\n",
        "test_data = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=test_transforms)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I2Mif_pJ87qE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading the image datasets and transforms with dataloaders\n",
        "# batch size for GPU on colab can be around 32 depending on size\n",
        "# but for this one we can go all the way up to 64\n",
        "batch_size = 64\n",
        "\n",
        "# sampler is being used because that is how we split the training and validation data\n",
        "  # shuffle == True due to under/overfitting\n",
        "  # (by default it's set true when using sampler)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxMtdvNzPYHs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Finding out the image info\n",
        " showing what type the images are and the subsequent shapes \n",
        " ### this is important because of tensor multiplication\n",
        "\n",
        "this shows that it's 64 x 1 x 28 x 28\n",
        "  meaning, it's got 64 images, 1 color chanel (gray scale), \n",
        "  and the image size is 28x28"
      ]
    },
    {
      "metadata": {
        "id": "q8wGtVSO89bi",
        "colab_type": "code",
        "outputId": "cdef713a-f73e-4e35-820a-f02f6446e071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# initializing an iterator to iterate over the training data\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_O5QkGhO81-",
        "colab_type": "code",
        "outputId": "0c496817-cc11-4c4d-c0b0-6b03e8d69686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(images[0].numpy().squeeze(), cmap=\"Greys_r\");"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKnSRCPw/pCu9J3g4cU8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bQFypsce9QB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Very basic feed forward Neural network using gradient descent"
      ]
    },
    {
      "metadata": {
        "id": "eUfM0x1M8_Ji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# building the classifier\n",
        "\n",
        "class Neural_Network(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "      \n",
        "  # inhereting __init__ from Pytorch's nn.Module\n",
        "      super().__init__()\n",
        "\n",
        "# first connected layer, starting out pretty big and getting smaller as\n",
        "# the model progresses (this is not a rule, some layers can be equal,\n",
        "# BUT the final layer HAS to fit your classification output number\n",
        "      self.full_connected_layer1 = nn.Linear(784, 256)\n",
        "      self.full_connected_layer2 = nn.Linear(256, 128)\n",
        "      self.full_connected_layer3 = nn.Linear(128, 64)\n",
        "\n",
        "# final layer, only has 10 outputs since that's how many \n",
        "# classifications we have in our dataset \n",
        "# ( there are only ten types of clothing options)\n",
        "      self.full_connected_layer4 = nn.Linear(64, 10)\n",
        "\n",
        "# Adding dropout to prevent overfitting (this \"drops out\" a certain percentage \n",
        "# of items you're training on to prevent the Model from memorizing some pattern\n",
        "# that we can't see (like the actual pattern of the images in the \n",
        "# folders AKA how they're loaded))\n",
        "      self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "# make sure input tensor is flattened (easiest way to this is this syntax -1)\n",
        "      x = x.view(x.shape[0], -1)\n",
        "# applying dropout to each hidden layer to prevent overfitting\n",
        "# using Rectified Linear Unit for the activation\n",
        "# and Softmax for the output layer\n",
        "      x = self.dropout(F.relu(self.full_connected_layer1(x)))\n",
        "      x = self.dropout(F.relu(self.full_connected_layer2(x)))\n",
        "      x = self.dropout(F.relu(self.full_connected_layer3(x)))\n",
        "      \n",
        "      x = F.log_softmax(self.ouput(x), dim=1)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_bNJyQH9CeL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# intializing the model from the class we just built\n",
        "model = Neural_Network()\n",
        "\n",
        "# using the NLLLoss as the criterion and Standard Gradient Descent as the optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DERCidZVTNFy",
        "colab_type": "code",
        "outputId": "8bd03e67-1d3d-4f49-9383-eeec76358426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "steps = 0\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        # Turn off gradients for validation\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images, labels in test_loader:\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        test_losses.append(test_loss/len(test_loader))\n",
        "\n",
        "        print(f'Epoch: {epoch+1}/{epochs}',\n",
        "              f'Training Loss: {train_losses[-1]:.4f}',\n",
        "              f'Test Loss: {test_losses[-1]:.4f}',\n",
        "              f'Test Accuracy: {(accuracy/len(test_loader)):.4f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10 Training Loss: 0.3235 Test Loss: 0.3870 Test Accuracy: 0.8658\n",
            "Epoch: 2/10 Training Loss: 0.3182 Test Loss: 0.3901 Test Accuracy: 0.8566\n",
            "Epoch: 3/10 Training Loss: 0.3176 Test Loss: 0.3958 Test Accuracy: 0.8588\n",
            "Epoch: 4/10 Training Loss: 0.3124 Test Loss: 0.3786 Test Accuracy: 0.8681\n",
            "Epoch: 5/10 Training Loss: 0.3119 Test Loss: 0.3640 Test Accuracy: 0.8730\n",
            "Epoch: 6/10 Training Loss: 0.3083 Test Loss: 0.3699 Test Accuracy: 0.8667\n",
            "Epoch: 7/10 Training Loss: 0.3052 Test Loss: 0.3792 Test Accuracy: 0.8686\n",
            "Epoch: 8/10 Training Loss: 0.3044 Test Loss: 0.3858 Test Accuracy: 0.8681\n",
            "Epoch: 9/10 Training Loss: 0.3014 Test Loss: 0.3710 Test Accuracy: 0.8688\n",
            "Epoch: 10/10 Training Loss: 0.2992 Test Loss: 0.3935 Test Accuracy: 0.8660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdQKAd8SVoZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notice how this is cool and all, but we really need to use this in the real world\n",
        "\n",
        " - That's where having a validation set (a test before the testing set) is extremely helpful\n",
        " - AND we need to save our model\n",
        "\n",
        "Here's a little preview of the saving. Check the CNN Basic model for some validation data"
      ]
    },
    {
      "metadata": {
        "id": "-4PSKTKGAw8D",
        "colab_type": "code",
        "outputId": "9c91467e-fa2b-40a3-c605-656b05b4e654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"The model: \\n\", model, '\\n')\n",
        "\n",
        "print(\"The state dict keys after training for 10 epochs: \\n\\n\", model.state_dict().keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model: \n",
            " Neural_Network(\n",
            "  (full_connected_layer1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (full_connected_layer2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (full_connected_layer3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (ouput): Linear(in_features=64, out_features=10, bias=True)\n",
            ") \n",
            "\n",
            "The state dict keys after training for 10 epochs: \n",
            "\n",
            " odict_keys(['full_connected_layer1.weight', 'full_connected_layer1.bias', 'full_connected_layer2.weight', 'full_connected_layer2.bias', 'full_connected_layer3.weight', 'full_connected_layer3.bias', 'ouput.weight', 'ouput.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c7y2PvDFWPgg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'toy_model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyKei6k1WWgR",
        "colab_type": "code",
        "outputId": "f313b9d0-ee67-463a-dd72-caa368c4ebc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# loading that model's .pth\n",
        "state_dict = torch.load('toy_model.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['full_connected_layer1.weight', 'full_connected_layer1.bias', 'full_connected_layer2.weight', 'full_connected_layer2.bias', 'full_connected_layer3.weight', 'full_connected_layer3.bias', 'ouput.weight', 'ouput.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T4jyEJZ_WcyM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loading the state dicitonary to a model\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}